{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vae_mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rautshree/AI-class/blob/master/vae_mnist.ipynb%20i.e%20%20GAN's\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "A4w4PRWgfC9t",
        "colab_type": "code",
        "outputId": "65a1c5b8-9ef4-40d1-f8dd-8cee228c57c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x58610000 @  0x7fac7d2752a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E05lIOwn_2KO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Intro to Variational Autoencoders**\n",
        "\n",
        "Autoencoders are neural networks that aims to copy their inputs to their outputs. They work by compressing the input into a latent-space representation, and then reconstructing the output from this representation.This kind of network is composed of two parts :\n",
        "\n",
        "1.  Encoder: This is the part of the network that compresses the input into a latent-space representation. It can be represented by an encoding function h=f(x).\n",
        "2.  Decoder: This part aims to reconstruct the input from the latent space representation. It can be represented by a decoding function r=g(h).\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "bi0O1uar_zPz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](https://cdn-images-1.medium.com/max/800/1*PVm-Y50e3HPOsD9my2sv4A.png)"
      ]
    },
    {
      "metadata": {
        "id": "grviWIOGAT18",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Variational Autoencoders can be thought of as an extension of Autoencoder algorithms that allow for learning distributions of data by adapting the network to perform variational inference that we learned about today in class. "
      ]
    },
    {
      "metadata": {
        "id": "mzaXdUcBBUGE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](http://kvfrans.com/content/images/2016/08/vae.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "1wWcZiH_Bdyd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In today's lab let's see how we can train a VAE on the familiar MNIST image dataset. Remember that the objective of VAE is to learn the distribution of the dataset and not just merely reconstructing the images. It would be helpful to keep the ideas of Variational Inference and the reparameterization trick, at the back of your mind while working on this experiment to have a thorough understanding of VAEs and Bayesian Neural Nets in general."
      ]
    },
    {
      "metadata": {
        "id": "SXMoy09-CV5z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2dXaHnhPeoky",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# prerequisites\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Batch size\n",
        "batch_size = 100\n",
        "\n",
        "## Load the MNIST dataset and apply tensor-transformation to both train and test data \n",
        "## Hint: Checkout documentation for \"torchvision.datasets.MNIST()\"\n",
        "# MNIST Dataset\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='../../data/',\n",
        "                                           train=True, \n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='../../data/',\n",
        "                                          train=False, \n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "## Setup a batch loader to fetch data batch by batch\n",
        "## Hint: Checkout \"torch.utils.data.DataLoader()\"\n",
        "# Data Loader (Input Pipeline)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HuJCGSVneolB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        \n",
        "        # encoder part\n",
        "        ## The encoder has to be a fully connected network with the following dimensions\n",
        "        ## x_dim -> h_dim1 -> h_dim2\n",
        "        self.fc1 = nn.Linear(x_dim, h_dim1)\n",
        "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
        "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
        "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
        "        \n",
        "       \n",
        "\n",
        "        \n",
        "        ## Sample mean and standard deviation with fully connected layers as\n",
        "        ## Mean : h_dim2 -> z_dim\n",
        "        ## Standard deviation : h_dim2 -> z_dim\n",
        "        '''\n",
        "        ENTER THE CODE HERE\n",
        "        '''\n",
        "\n",
        "        # decoder part\n",
        "        ## Decoder net has fully connected layers of the following shapes\n",
        "        ## z_dim -> h_dim2 -> h_dim1 -> x_dim\n",
        "        self.fc4 = nn.Linear(z_dim, h_dim2)\n",
        "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
        "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
        "        \n",
        "    def encoder(self, x):\n",
        "        ## Relu at the right points\n",
        "        h = F.relu(self.fc1(x))\n",
        "        h = F.relu(self.fc2(h))\n",
        "        return self.fc31(h), self.fc32(h)   \n",
        "        \n",
        "    def sampling(self, mu, log_var):\n",
        "        std = torch.exp(0.5*log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        return eps.mul(std).add_(mu) # return z sample\n",
        "        \n",
        "    def decoder(self, z):\n",
        "        ## ReLu at the right points. FInaloutput has to have a sigmoid activation\n",
        "        h = F.relu(self.fc4(z))\n",
        "        h = F.relu(self.fc5(h))\n",
        "        return F.sigmoid(self.fc6(h)) \n",
        "    \n",
        "    def forward(self, x):\n",
        "        mu, log_var = self.encoder(x.view(-1, 784))\n",
        "        z = self.sampling(mu, log_var)\n",
        "        return self.decoder(z), mu, log_var\n",
        "\n",
        "# build model\n",
        "vae = VAE(x_dim=784, h_dim1= 512, h_dim2=256, z_dim=2)\n",
        "if torch.cuda.is_available():\n",
        "    vae.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qBDUeaUleolJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "ce203a95-486b-47c2-c463-628e529c152c"
      },
      "cell_type": "code",
      "source": [
        "vae"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VAE(\n",
              "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (fc31): Linear(in_features=256, out_features=2, bias=True)\n",
              "  (fc32): Linear(in_features=256, out_features=2, bias=True)\n",
              "  (fc4): Linear(in_features=2, out_features=256, bias=True)\n",
              "  (fc5): Linear(in_features=256, out_features=512, bias=True)\n",
              "  (fc6): Linear(in_features=512, out_features=784, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "u4bSGBK4eolX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(vae.parameters())\n",
        "# return reconstruction error + KL divergence losses\n",
        "def loss_function(recon_x, x, mu, log_var):\n",
        "    ## calculate Binary cross entropy between recon_x and x\n",
        "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
        "    \n",
        "    ## The following is the closed form solution to compute KL Divergence\n",
        "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "    return BCE + KLD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g38p4K5ieole",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    vae.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = data.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        ## Pass \"data\" as input to \"vae\" and collect the output -> \"recon_batch, mu, log_var\"\n",
        "       \n",
        "        recon_batch, mu, log_var = vae(data)\n",
        "   \n",
        "        \n",
        "        loss = loss_function(recon_batch, data, mu, log_var)\n",
        "        \n",
        "        ## Start the backpropagation here.\n",
        "        ## backward() on what?\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item() / len(data)))\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ak7lkclLeolk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test():\n",
        "    vae.eval()\n",
        "    test_loss= 0\n",
        "    with torch.no_grad():\n",
        "        for data, _ in test_loader:\n",
        "            data = data.cuda()\n",
        "            recon, mu, log_var = vae(data)\n",
        "            \n",
        "            # sum up batch loss\n",
        "            test_loss += loss_function(recon, data, mu, log_var).item()\n",
        "        \n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('====> Test set loss: {:.4f}'.format(test_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "g-OVDJ95eolq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1302
        },
        "outputId": "43af8ac7-de9a-47ed-f86d-d0665006fcde"
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 10):\n",
        "    train(epoch)\n",
        "    test()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 546.230859\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 191.222813\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 177.485996\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 169.462832\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 175.308145\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 155.477207\n",
            "====> Epoch: 1 Average loss: 181.4889\n",
            "====> Test set loss: 163.4073\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 161.396045\n",
            "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 161.566133\n",
            "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 149.580127\n",
            "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 154.630908\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 163.046045\n",
            "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 157.332617\n",
            "====> Epoch: 2 Average loss: 159.2320\n",
            "====> Test set loss: 155.2137\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 156.467910\n",
            "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 148.113555\n",
            "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 160.048428\n",
            "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 153.964678\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 151.724355\n",
            "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 154.270088\n",
            "====> Epoch: 3 Average loss: 153.0579\n",
            "====> Test set loss: 150.9700\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 143.851348\n",
            "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 141.765820\n",
            "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 147.883857\n",
            "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 144.284189\n",
            "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 148.231826\n",
            "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 149.784668\n",
            "====> Epoch: 4 Average loss: 149.3841\n",
            "====> Test set loss: 148.4576\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 147.957988\n",
            "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 149.503037\n",
            "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 139.473740\n",
            "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 143.305137\n",
            "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 146.678770\n",
            "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 146.505010\n",
            "====> Epoch: 5 Average loss: 147.1913\n",
            "====> Test set loss: 147.0991\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 151.727998\n",
            "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 148.420215\n",
            "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 155.129219\n",
            "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 149.166152\n",
            "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 131.729248\n",
            "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 136.419512\n",
            "====> Epoch: 6 Average loss: 145.7113\n",
            "====> Test set loss: 145.7974\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 145.249492\n",
            "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 142.431602\n",
            "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 142.965264\n",
            "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 151.986094\n",
            "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 149.468008\n",
            "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 144.754805\n",
            "====> Epoch: 7 Average loss: 144.5564\n",
            "====> Test set loss: 145.0806\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 143.585000\n",
            "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 142.631592\n",
            "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 151.760146\n",
            "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 141.265010\n",
            "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 152.321270\n",
            "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 142.950732\n",
            "====> Epoch: 8 Average loss: 143.5560\n",
            "====> Test set loss: 143.9001\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 153.096934\n",
            "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 136.102588\n",
            "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 145.172383\n",
            "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 138.951045\n",
            "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 147.696963\n",
            "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 143.036445\n",
            "====> Epoch: 9 Average loss: 142.7443\n",
            "====> Test set loss: 143.7980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UD7Y5ESDeol2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "b9253e44-573a-4d7b-c000-5b297c3a03d2"
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "with torch.no_grad():\n",
        "    z = torch.randn(64, 2).cuda()\n",
        "    sample = vae.decoder(z).cuda()\n",
        "    #print(sample.shape)\n",
        "    sample=sample.view(64,28,28,1)[4].cpu().numpy()\n",
        "    print(sample.shape)\n",
        "    #save_image(sample.view(64, 1, 28, 28), './samples/sample_' + '.png')\n",
        "    cv2.imwrite('1.png',sample)\n",
        "    from google.colab import files\n",
        "    files.download('1.png')\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Sa8mBk25gqkr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}