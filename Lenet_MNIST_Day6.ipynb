{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lenet_MNIST_Day6.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rautshree/AI-class/blob/master/Lenet_MNIST_Day6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "7AYJYPJXcPxf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**LeNet for MNIST Handwritten character recognition**\n"
      ]
    },
    {
      "metadata": {
        "id": "hHMUokaZcigq",
        "colab_type": "code",
        "outputId": "b5eab184-a429-419a-fa33-6054869e9fe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cu92\n",
            "\tlibcudart.so (libc6,x86-64) => /usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudart.so\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9vT1rL7Rcr64",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "# How to choose between CPU and GPU?\n",
        "# Use torch.cuda.is_available() and torch.device() to assign the device (CPU/GPU) to a variable \n",
        "# named device.   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eUwvBAHbdX4R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*   cuda.is_available  = [Link](https://pytorch.org/docs/stable/cuda.html#torch.cuda.is_available)\n",
        "*   device = [Link](https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.device)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "sPOF_Bqdd-kc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CqQ7-rxirrtg",
        "colab_type": "code",
        "outputId": "f6f9343b-5dc1-4199-dac3-ca59effd1eb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x59386000 @  0x7fb906a232a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tm_Zb0R_lbro",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#device=torch.device('cuda')\n",
        "#torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dlIy9LgbbR3L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Play around with the hyperparams below\n",
        "# Hyper parameters\n",
        "num_epochs = 2\n",
        "num_classes = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.000001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rgLQzhWycoE3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The dataset we are going to work on is MNIST handwritten characters dataset.\n",
        "# Follow the api in the below link to load the MNIST dataset in torchvision.datasets\n",
        "# train_loader and test_loader need to use the dataloader api to have a batch wise data loading function\n",
        "# Try to understand how batch wise training works by thinking about how training was done in the previous ML experiements "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wXifFff7536M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*   torchvision.datasets.MNIST = [Link](https://pytorch.org/docs/stable/torchvision/datasets.html#mnist)\n",
        "*   torch.utils.data.DataLoader = [Link](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)\n"
      ]
    },
    {
      "metadata": {
        "id": "eVk-7nTJd79g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# MNIST dataset\n",
        "# Checkout possible transforms. Data augmentation can help improve accuracy in most cases.\n",
        "# Explore any of the options available. Try to understand what they all do\n",
        "train_dataset = torchvision.datasets.MNIST(root='../../data/',\n",
        "                                           train=True, \n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='../../data/',\n",
        "                                          train=False, \n",
        "                                          transform=transforms.ToTensor())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j9SyvqvJbgy2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Try to add a cell below to see how the batch loader outputs data\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "--9iRR0u70yT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lets try to build  the network architecture from the given image.\n",
        "\n",
        "\n",
        "1st layer:\n",
        "\n",
        "Convolution layer:\n",
        "\n",
        ">in_channels = 1\n",
        ">out_channels = 16\n",
        ">kernel_size = 5\n",
        ">stride = 1\n",
        ">padding = 2\n",
        "\n",
        "Batchnorm features = 16\n",
        "\n",
        "Maxpool layer:\n",
        "\n",
        ">kernel size= 2\n",
        ">stride = 2\n",
        " \n",
        " \n",
        "2nd layer:\n",
        "\n",
        "Convolution layer:\n",
        "\n",
        ">in_channels = 16\n",
        ">out_channels = 32\n",
        ">kernel_size = 5\n",
        ">stride = 1\n",
        ">padding = 2\n",
        "\n",
        "Batchnorm features = 32\n",
        "\n",
        "Maxpool layer:\n",
        "\n",
        ">kernel size= 2\n",
        ">stride = 2\n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "OpOcpqc97qJx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](https://pytorch.org/tutorials/_images/mnist.png)"
      ]
    },
    {
      "metadata": {
        "id": "t5_OmAtxbjwV",
        "colab_type": "code",
        "outputId": "1a89deb6-0762-45fb-e600-e0b79326c627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Convolutional neural network (two convolutional layers)\n",
        "# What does each layer do? Try to understand the significance of each operation\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=7, stride=1, padding=3),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.fc = nn.Linear(7*7*32, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        ## Design the flow graph here\n",
        "        # x here is the data\n",
        "        # the transformations that need to be done are the 5 layers in sequence.\n",
        "        # You might have to reshape the vector before the fully connected layers\n",
        "        #out = ##Enter the code here##\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "model = ConvNet(num_classes).to(device)\n",
        "print(model)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ConvNet(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=1568, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Jo6mBtWPby2n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "# WHat are the other losses that are available?\n",
        "# Is cross entropy loss the best option?\n",
        "# How should one choose the loss function?\n",
        "# Ask TA or Professor, if you do not answers to these. Must know.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "haa7Ttl5b60m",
        "colab_type": "code",
        "outputId": "065c44cb-4a3e-4aa9-f9e8-dfeca5909ed5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "      \n",
        "        ## Pytorch has an easy method to convert data format to be compatible between CPU and GPU.\n",
        "        # Convert the data vectors to the \"device\" type\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        # Note how the output is extracted from the network in the line below.\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/2], Step [100/600], Loss: 2.3316\n",
            "Epoch [1/2], Step [200/600], Loss: 2.3368\n",
            "Epoch [1/2], Step [300/600], Loss: 2.3129\n",
            "Epoch [1/2], Step [400/600], Loss: 2.2207\n",
            "Epoch [1/2], Step [500/600], Loss: 2.2036\n",
            "Epoch [1/2], Step [600/600], Loss: 2.2494\n",
            "Epoch [2/2], Step [100/600], Loss: 2.1613\n",
            "Epoch [2/2], Step [200/600], Loss: 2.1669\n",
            "Epoch [2/2], Step [300/600], Loss: 2.1814\n",
            "Epoch [2/2], Step [400/600], Loss: 2.1021\n",
            "Epoch [2/2], Step [500/600], Loss: 2.0933\n",
            "Epoch [2/2], Step [600/600], Loss: 2.0768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9wRKdgIPb_YV",
        "colab_type": "code",
        "outputId": "bc143bf5-9729-4e48-c4d9-980108c2b274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 41.95 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "85aUFT-WcGYX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save the model checkpoint\n",
        "torch.save(model.state_dict(), 'model.ckpt')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}